{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComparisonDataset(Dataset):\n",
    "    def __init__(self, data_len):\n",
    "        self.data_len = data_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = random.random()\n",
    "        y1 = random.random()\n",
    "        y2 = random.random()\n",
    "        if abs(y1 - x) > abs(y2 - x):\n",
    "            chosen = torch.tensor([x, y2])\n",
    "            rejected = torch.tensor([x, y1])\n",
    "        else:\n",
    "            chosen = torch.tensor([x, y1])\n",
    "            rejected = torch.tensor([x, y2])\n",
    "        \n",
    "        return chosen, rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ComparisonDataset(200000)\n",
    "data_loader = DataLoader(dataset, batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP input: (x, y), output scalar reward\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 0.6887573003768921\n",
      "100 loss: 0.6224793195724487\n",
      "200 loss: 0.5490990877151489\n",
      "300 loss: 0.393026739358902\n",
      "400 loss: 0.26217490434646606\n",
      "500 loss: 0.20685604214668274\n",
      "600 loss: 0.13266679644584656\n",
      "700 loss: 0.13813342154026031\n",
      "800 loss: 0.16788017749786377\n",
      "900 loss: 0.10095753520727158\n",
      "1000 loss: 0.10350020229816437\n",
      "1100 loss: 0.09711901098489761\n",
      "1200 loss: 0.12045450508594513\n",
      "1300 loss: 0.06185797601938248\n",
      "1400 loss: 0.0990157276391983\n",
      "1500 loss: 0.13050368428230286\n",
      "1600 loss: 0.11660881340503693\n",
      "1700 loss: 0.07478947937488556\n",
      "1800 loss: 0.09369362890720367\n",
      "1900 loss: 0.04702315106987953\n",
      "2000 loss: 0.06259207427501678\n",
      "2100 loss: 0.06624438613653183\n",
      "2200 loss: 0.04136281460523605\n",
      "2300 loss: 0.024363122880458832\n",
      "2400 loss: 0.03977678343653679\n",
      "2500 loss: 0.085675910115242\n",
      "2600 loss: 0.013221899047493935\n",
      "2700 loss: 0.04432803764939308\n",
      "2800 loss: 0.06046494096517563\n",
      "2900 loss: 0.06497308611869812\n",
      "3000 loss: 0.03227042406797409\n",
      "3100 loss: 0.030278358608484268\n",
      "3200 loss: 0.033947061747312546\n",
      "3300 loss: 0.031508881598711014\n",
      "3400 loss: 0.019298722967505455\n",
      "3500 loss: 0.06942899525165558\n",
      "3600 loss: 0.043263860046863556\n",
      "3700 loss: 0.018004152923822403\n",
      "3800 loss: 0.022464793175458908\n",
      "3900 loss: 0.03493841364979744\n",
      "4000 loss: 0.0032645855098962784\n",
      "4100 loss: 0.01660826988518238\n",
      "4200 loss: 0.03545688837766647\n",
      "4300 loss: 0.02012302353978157\n",
      "4400 loss: 0.07754568010568619\n",
      "4500 loss: 0.045088671147823334\n",
      "4600 loss: 0.004588545765727758\n",
      "4700 loss: 0.029546860605478287\n",
      "4800 loss: 0.0022400259040296078\n",
      "4900 loss: 0.021776091307401657\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for idx, (chosen_batch, rejected_batch) in enumerate(data_loader):\n",
    "    optim.zero_grad()\n",
    "    chosen_reward = model(chosen_batch)\n",
    "    rejected_reward = model(rejected_batch)\n",
    "    loss = (-torch.log(nn.functional.sigmoid(chosen_reward - rejected_reward))).mean()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if idx % 100 == 0:\n",
    "        print(f\"{idx} loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=16, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([76.9150], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "demo_input = torch.tensor([0.5, 0.5])\n",
    "print(model(demo_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([76.0057], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "demo_input = torch.tensor([0.5, 0.51])\n",
    "print(model(demo_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([68.4210], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "demo_input = torch.tensor([0.5, 0.4])\n",
    "print(model(demo_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([67.8225], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "demo_input = torch.tensor([0.5, 0.6])\n",
    "print(model(demo_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([58.7301], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "demo_input = torch.tensor([0.5, 0.7])\n",
    "print(model(demo_input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
